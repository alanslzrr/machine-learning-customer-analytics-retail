{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final — Inferencia sobre Datos Nuevos\n",
    "\n",
    "En este notebook aplicamos los modelos entrenados sobre datos nuevos para evaluar su capacidad de generalización. El flujo garantiza coherencia con el entrenamiento mediante la reutilización de pipelines y metadatos, permitiendo inferencia reproducible sobre cualquier dataset con la estructura esperada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración y dependencias\n",
    "\n",
    "Definimos las rutas a los artefactos entrenados y al dataset de inferencia. Para aplicar el modelo sobre datos nuevos, modificamos `DATA_FILE` apuntando al archivo correspondiente manteniendo la misma estructura de columnas del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Tuple\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de la tarea\n",
    "TAREA: Literal[\"clasificacion\", \"regresion\"] = \"clasificacion\"\n",
    "\n",
    "# Rutas - Modificar DATA_FILE para aplicar sobre datos nuevos\n",
    "DATA_FILE = Path(\"data/interim/supermercado_limpio.csv\")\n",
    "\n",
    "MODEL_FILE = Path(\"models/pipeline_clasificacion_sin_leakage.pkl\") if TAREA == \"clasificacion\" else Path(\"models/pipeline_regresion_sin_leakage.pkl\")\n",
    "\n",
    "METADATA_FILE = Path(\"models/pipeline_metadata.pkl\")\n",
    "TARGET_COL = \"respuesta\" if TAREA == \"clasificacion\" else \"gasto_total\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset de inferencia\n",
    "\n",
    "Cargamos el dataset sobre el cual aplicaremos el modelo. Este debe tener la misma estructura de columnas que el dataset de entrenamiento, aunque pueden diferir en el número de observaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 1982 observaciones, 48 variables\n",
      "Variable objetivo disponible: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educacion</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>hijos_casa</th>\n",
       "      <th>recencia</th>\n",
       "      <th>gasto_vinos</th>\n",
       "      <th>gasto_frutas</th>\n",
       "      <th>gasto_carnes</th>\n",
       "      <th>gasto_pescado</th>\n",
       "      <th>gasto_dulces</th>\n",
       "      <th>...</th>\n",
       "      <th>tasa_compra_online</th>\n",
       "      <th>tasa_compra_oferta</th>\n",
       "      <th>ticket_promedio</th>\n",
       "      <th>tamano_hogar</th>\n",
       "      <th>tiene_dependientes</th>\n",
       "      <th>hogar_unipersonal</th>\n",
       "      <th>ratio_compras_online</th>\n",
       "      <th>tiene_pareja</th>\n",
       "      <th>educacion_x_estado</th>\n",
       "      <th>anio_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Casado</td>\n",
       "      <td>53359.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.286</td>\n",
       "      <td>18.36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>21474.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>11.38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Divorciado</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>17.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Union_Libre</td>\n",
       "      <td>64504.0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>986</td>\n",
       "      <td>36</td>\n",
       "      <td>168</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.280</td>\n",
       "      <td>52.56</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Casado</td>\n",
       "      <td>65169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1074</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.036</td>\n",
       "      <td>42.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   educacion estado_civil  ingresos  hijos_casa  recencia  gasto_vinos  \\\n",
       "0          3       Casado   53359.0           2         4          173   \n",
       "1          3      Soltero   21474.0           1         0            6   \n",
       "2          3   Divorciado   41411.0           0        11           37   \n",
       "3          5  Union_Libre   64504.0           3        81          986   \n",
       "4          3       Casado   65169.0           0        23         1074   \n",
       "\n",
       "   gasto_frutas  gasto_carnes  gasto_pescado  gasto_dulces  ...  \\\n",
       "0             4            30              3             6  ...   \n",
       "1            16            24             11             0  ...   \n",
       "2            32            38             11             3  ...   \n",
       "3            36           168             16             0  ...   \n",
       "4             0            69              0             0  ...   \n",
       "\n",
       "   tasa_compra_online  tasa_compra_oferta  ticket_promedio  tamano_hogar  \\\n",
       "0               0.429               0.286            18.36             3   \n",
       "1               0.500               0.250            11.38             2   \n",
       "2               0.375               0.125            17.38             1   \n",
       "3               0.560               0.280            52.56             4   \n",
       "4               0.500               0.036            42.46             1   \n",
       "\n",
       "   tiene_dependientes  hogar_unipersonal  ratio_compras_online  tiene_pareja  \\\n",
       "0                   1                  0              0.428571             1   \n",
       "1                   1                  0              0.500000             0   \n",
       "2                   0                  1              0.375000             0   \n",
       "3                   1                  0              0.560000             1   \n",
       "4                   0                  1              0.500000             1   \n",
       "\n",
       "   educacion_x_estado  anio_alta  \n",
       "0                   3       2013  \n",
       "1                   0       2014  \n",
       "2                   0       2013  \n",
       "3                   5       2013  \n",
       "4                   3       2014  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert DATA_FILE.exists(), f\"Dataset no encontrado: {DATA_FILE}\"\n",
    "\n",
    "df_raw = pd.read_csv(DATA_FILE)\n",
    "\n",
    "print(f\"Dataset cargado: {df_raw.shape[0]} observaciones, {df_raw.shape[1]} variables\")\n",
    "\n",
    "print(f\"Variable objetivo disponible: {TARGET_COL in df_raw.columns}\")\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de artefactos de entrenamiento\n",
    "\n",
    "Cargamos el pipeline entrenado y los metadatos que contienen información sobre las features esperadas, transformaciones aplicadas y configuración del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline cargado: Pipeline\n",
      "Umbral de clasificación: 0.2069\n"
     ]
    }
   ],
   "source": [
    "assert METADATA_FILE.exists(), f\"Metadatos no encontrados: {METADATA_FILE}\"\n",
    "assert MODEL_FILE.exists(), f\"Modelo no encontrado: {MODEL_FILE}\"\n",
    "\n",
    "metadata = joblib.load(METADATA_FILE)\n",
    "model = joblib.load(MODEL_FILE)\n",
    "\n",
    "\n",
    "print(f\"Pipeline cargado: {type(model).__name__}\")\n",
    "\n",
    "if TAREA == \"clasificacion\":    print(f\"Umbral de clasificación: {metadata.get('clf_threshold', 0.5):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares\n",
    "\n",
    "Definimos funciones para validar y preparar las features del dataset de inferencia, garantizando alineación exacta con el espacio de features utilizado durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "\n",
    "\n",
    "def validar_columnas(work: pd.DataFrame, expected: list[str], contexto: str, allow_extras: bool = False) -> pd.DataFrame:\n",
    "    # Verifica alineación de columnas; opcionalmente descarta extras\n",
    "    faltantes = [c for c in expected if c not in work.columns]\n",
    "    extras = [c for c in work.columns if c not in expected]\n",
    "    if faltantes:\n",
    "        msg = (\n",
    "            f\"Desalineación de columnas en {contexto}. \"\n",
    "            f\"Faltantes: {faltantes or 'ninguna'} | Extras: {extras or 'ninguna'}\"\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "    if extras and not allow_extras:\n",
    "        msg = (\n",
    "            f\"Desalineación de columnas en {contexto}. \"\n",
    "            f\"Faltantes: {faltantes or 'ninguna'} | Extras: {extras or 'ninguna'}\"\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "    if extras:\n",
    "        print(f\"Descartamos columnas extra en {contexto}: {extras}\")\n",
    "        work = work.drop(columns=extras)\n",
    "    return work[expected]\n",
    "\n",
    "\n",
    "def preparar_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series | None]:\n",
    "    work = df.drop(columns=[TARGET_COL], errors=\"ignore\").copy()\n",
    "    for col in work.columns:\n",
    "        if str(work[col].dtype) == \"Int64\":\n",
    "            work[col] = work[col].astype(\"int64\")\n",
    "    target = df[TARGET_COL] if TARGET_COL in df.columns else None\n",
    "    return work, target\n",
    "\n",
    "\n",
    "def preparar_regresion(df: pd.DataFrame, meta: dict) -> Tuple[pd.DataFrame, pd.Series | None]:\n",
    "    work = df.drop(columns=[TARGET_COL], errors=\"ignore\").copy()\n",
    "    expected = meta.get(\"reg_raw_feature_names\") or meta[\"raw_feature_names\"]\n",
    "    work = validar_columnas(work, expected, \"regresion (features crudas)\", allow_extras=True)\n",
    "    for col in work.columns:\n",
    "        if str(work[col].dtype) == \"Int64\":\n",
    "            work[col] = work[col].astype(\"int64\")\n",
    "    target = df[TARGET_COL] if TARGET_COL in df.columns else None\n",
    "    return work, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del dataset para inferencia\n",
    "\n",
    "Extraemos las features y la variable objetivo (si está disponible), validando que las columnas coincidan con las esperadas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features preparadas: 1982 observaciones, 47 variables\n",
      "Target disponible: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observaciones</th>\n",
       "      <th>features</th>\n",
       "      <th>target_disponible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observaciones  features  target_disponible\n",
       "0           1982        47               True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinar columnas esperadas\n",
    "preproc = getattr(model, \"named_steps\", {}).get(\"preprocess\") if hasattr(model, \"named_steps\") else None\n",
    "preproc_cols = []\n",
    "if preproc is not None and hasattr(preproc, \"transformers_\"):\n",
    "    for _, _, cols in preproc.transformers_:\n",
    "        if cols == \"drop\" or cols is None:\n",
    "            continue\n",
    "        if isinstance(cols, (list, tuple)):\n",
    "            preproc_cols.extend(list(cols))\n",
    "        else:\n",
    "            try:\n",
    "                preproc_cols.extend(list(cols))\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "# Preparar features según tarea\n",
    "if TAREA == \"clasificacion\":\n",
    "    X_inf, y_inf = preparar_features(df_raw)\n",
    "    expected_cols = metadata.get(\"raw_feature_names\", [])\n",
    "    if preproc_cols:\n",
    "        expected_cols = list(set(expected_cols) | set(preproc_cols))\n",
    "    X_inf = validar_columnas(X_inf, expected_cols, \"clasificacion\", allow_extras=True)\n",
    "elif TAREA == \"regresion\":\n",
    "    X_inf, y_inf = preparar_regresion(df_raw, metadata)\n",
    "    expected_cols = metadata.get(\"reg_raw_feature_names\") or metadata.get(\"raw_feature_names\", [])\n",
    "    if preproc_cols:\n",
    "        expected_cols = list(set(expected_cols) | set(preproc_cols))\n",
    "    X_inf = validar_columnas(X_inf, expected_cols, \"regresion\", allow_extras=True)\n",
    "else:\n",
    "    raise ValueError(f\"Tarea no reconocida: {TAREA}\")\n",
    "\n",
    "print(f\"Features preparadas: {X_inf.shape[0]} observaciones, {X_inf.shape[1]} variables\")\n",
    "print(f\"Target disponible: {y_inf is not None}\")\n",
    "\n",
    "# Resumen\n",
    "resumen_dimensiones = pd.DataFrame({\n",
    "    \"observaciones\": [X_inf.shape[0]],\n",
    "    \"features\": [X_inf.shape[1]],\n",
    "    \"target_disponible\": [y_inf is not None]\n",
    "})\n",
    "resumen_dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de predicciones\n",
    "\n",
    "Aplicamos el pipeline entrenado sobre el dataset de inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral aplicado: 0.2069\n"
     ]
    }
   ],
   "source": [
    "if TAREA == \"clasificacion\":\n",
    "    y_pred_proba = model.predict_proba(X_inf)[:, 1]\n",
    "    clf_threshold = float(metadata.get(\"clf_threshold\", 0.5))\n",
    "    y_pred = (y_pred_proba >= clf_threshold).astype(int)\n",
    "    \n",
    "    print(f\"Umbral aplicado: {clf_threshold:.4f}\")\n",
    "    distrib_pred = pd.Series(y_pred).value_counts().sort_index().to_frame(\"Frecuencia\")\n",
    "    distrib_pred[\"Porcentaje\"] = (distrib_pred[\"Frecuencia\"] / len(y_pred) * 100).round(2)\n",
    "    distrib_pred.index = [\"No Responde\", \"Responde\"]\n",
    "    distrib_pred\n",
    "else:\n",
    "    y_pred = model.predict(X_inf)\n",
    "    \n",
    "    print(\"Estadísticas de las predicciones:\")\n",
    "    resumen_pred = pd.DataFrame({\n",
    "        \"y_pred\": pd.Series(y_pred).describe(),\n",
    "    })\n",
    "    resumen_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de métricas\n",
    "\n",
    "Si el dataset incluye la variable objetivo, calculamos las métricas de rendimiento para evaluar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TAREA == \"clasificacion\":\n",
    "    y_pred_proba = model.predict_proba(X_inf)[:, 1]\n",
    "    clf_threshold = float(metadata.get(\"clf_threshold\", 0.5))\n",
    "    y_pred = (y_pred_proba >= clf_threshold).astype(int)\n",
    "elif TAREA == \"regresion\":\n",
    "    expected_cols = metadata.get(\"reg_raw_feature_names\") or metadata.get(\"raw_feature_names\", [])\n",
    "    X_inf = validar_columnas(X_inf, expected_cols, \"regresion (features crudas)\", allow_extras=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inferencia</th>\n",
       "      <td>0.981213</td>\n",
       "      <td>0.935923</td>\n",
       "      <td>0.715493</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC  Accuracy  Precision    Recall   F1\n",
       "inferencia  0.981213  0.935923   0.715493  0.907143  0.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if y_inf is not None:\n",
    "    if TAREA == \"clasificacion\":\n",
    "        metrics_clf = pd.DataFrame({\n",
    "            \"AUC\": [roc_auc_score(y_inf, y_pred_proba)],\n",
    "            \"Accuracy\": [accuracy_score(y_inf, y_pred)],\n",
    "            \"Precision\": [precision_score(y_inf, y_pred)],\n",
    "            \"Recall\": [recall_score(y_inf, y_pred)],\n",
    "            \"F1\": [f1_score(y_inf, y_pred)],\n",
    "        }, index=[\"inferencia\"])\n",
    "        \n",
    "        matriz_confusion = pd.DataFrame(\n",
    "            confusion_matrix(y_inf, y_pred),\n",
    "            index=[\"Real 0\", \"Real 1\"],\n",
    "            columns=[\"Pred 0\", \"Pred 1\"],\n",
    "        )\n",
    "        display(metrics_clf)\n",
    "        matriz_confusion\n",
    "    else:\n",
    "        baseline_mae = (y_inf - y_inf.mean()).abs().mean()\n",
    "        baseline_rmse = ((y_inf - y_inf.mean()) ** 2).mean() ** 0.5\n",
    "        mae = mean_absolute_error(y_inf, y_pred)\n",
    "        rmse = mean_squared_error(y_inf, y_pred) ** 0.5\n",
    "        r2 = r2_score(y_inf, y_pred)\n",
    "        \n",
    "        metrics_reg = pd.DataFrame({\n",
    "            \"MAE\": [mae],\n",
    "            \"RMSE\": [rmse],\n",
    "            \"R2\": [r2],\n",
    "            \"baseline_MAE\": [baseline_mae],\n",
    "            \"baseline_RMSE\": [baseline_rmse],\n",
    "        }, index=[\"inferencia\"])\n",
    "        \n",
    "        display(metrics_reg)\n",
    "        distrib_pred = pd.DataFrame({\n",
    "            \"y_real\": y_inf.describe(),\n",
    "            \"y_pred\": pd.Series(y_pred).describe(),\n",
    "        })\n",
    "        distrib_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Síntesis\n",
    "\n",
    "Cargamos los pipelines entrenados y aplicamos las predicciones sobre el dataset de inferencia. Si está disponible la variable objetivo, calculamos las métricas correspondientes para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El notebook carga el pipeline entrenado y genera predicciones sobre el dataset de inferencia. Las métricas obtenidas permiten evaluar el desempeño del modelo sobre datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
